{
  "license": "Apache License, Version 2.0",
  "copyright": "Copyright 2018 Google Inc.",
  "nbformat": "4",
  "nbformat_minor": "0",
  "metadata": {
    "colab": {
      "name": "DT To Table",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUZM0kQSYBM4",
        "colab_type": "text"
      },
      "source": [
        "#1. Install Dependencies\n",
        "First install the libraries needed to execute recipes, this only needs to be done once, then click play.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmCV5gg6uVZ2",
        "colab_type": "code"
      },
      "source": [
        "!pip install git+https://github.com/google/starthinker\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCBoC2yymTjI",
        "colab_type": "text"
      },
      "source": [
        "#2. Get Cloud Project ID\n",
        "To run this recipe [requires a Google Cloud Project](https://github.com/google/starthinker/blob/master/tutorials/cloud_project.md), this only needs to be done once, then click play.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9vgNO4LR88g",
        "colab_type": "code"
      },
      "source": [
        "CLOUD_PROJECT = 'PASTE PROJECT ID HERE'\n",
        "\n",
        "print(\"Cloud Project Set To: %s\" % CLOUD_PROJECT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfEFvwbdfViC",
        "colab_type": "text"
      },
      "source": [
        "#3. Get Client Credentials\n",
        "To read and write to various endpoints requires [downloading client credentials](https://github.com/google/starthinker/blob/master/tutorials/cloud_client_installed.md), this only needs to be done once, then click play.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvHxSrXDgCW1",
        "colab_type": "code"
      },
      "source": [
        "CLIENT_CREDENTIALS = 'PASTE CREDENTIALS HERE'\n",
        "\n",
        "print(\"Client Credentials Set To: %s\" % CLIENT_CREDENTIALS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjZ9A1qEUOMr",
        "colab_type": "text"
      },
      "source": [
        "#4. Enter DT To Table Parameters\n",
        "Move data from a DT bucket into a BigQuery table.\n",
        " 1. Ensure your user has <a href='https://developers.google.com/doubleclick-advertisers/dtv2/getting-started' target='_blank'>access to the bucket</a>.\n",
        " 1. Provide the DT bucket name to read from.\n",
        " 1. Provide the path of the files to read.\n",
        " 1. Each file is synchronized to a unique table.  Use a view or aggregate select.\n",
        "Modify the values below for your use case, can be done multiple times, then click play.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWdKticMkt3e",
        "colab_type": "code"
      },
      "source": [
        "FIELDS = {\n",
        "  \"bucket\":\"\", # Name of bucket where DT files are stored.\n",
        "  \"paths\":[], # List of prefixes to pull specific DT files.\n",
        "  \"days\":2, # Number of days back to synchronize.\n",
        "  \"hours\":0, # Number of hours back to synchronize.\n",
        "  \"dataset\":\"\", # Existing dataset in BigQuery.\n",
        "}\n",
        "\n",
        "print(\"Parameters Set To: %s\" % FIELDS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSjW3N1fAMMt",
        "colab_type": "text"
      },
      "source": [
        "#4. Execute DT To Table\n",
        "This does NOT need to be modified unles you are changing the recipe, click play.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krckBvh1oAWn",
        "colab_type": "code"
      },
      "source": [
        "from starthinker.util.project import project\n",
        "from starthinker.script.parse import json_set_fields\n",
        "\n",
        "USER_CREDENTIALS = '/content/user.json'\n",
        "\n",
        "TASKS = [\n",
        "  {\n",
        "    \"dt\": {\n",
        "      \"auth\": \"user\",\n",
        "      \"from\": {\n",
        "        \"bucket\": {\n",
        "          \"field\": {\n",
        "            \"name\": \"bucket\",\n",
        "            \"kind\": \"string\",\n",
        "            \"order\": 1,\n",
        "            \"default\": \"\",\n",
        "            \"description\": \"Name of bucket where DT files are stored.\"\n",
        "          }\n",
        "        },\n",
        "        \"paths\": {\n",
        "          \"field\": {\n",
        "            \"name\": \"paths\",\n",
        "            \"kind\": \"string_list\",\n",
        "            \"order\": 2,\n",
        "            \"default\": [],\n",
        "            \"description\": \"List of prefixes to pull specific DT files.\"\n",
        "          }\n",
        "        },\n",
        "        \"days\": {\n",
        "          \"field\": {\n",
        "            \"name\": \"days\",\n",
        "            \"kind\": \"integer\",\n",
        "            \"order\": 3,\n",
        "            \"default\": 2,\n",
        "            \"description\": \"Number of days back to synchronize.\"\n",
        "          }\n",
        "        },\n",
        "        \"hours\": {\n",
        "          \"field\": {\n",
        "            \"name\": \"hours\",\n",
        "            \"kind\": \"integer\",\n",
        "            \"order\": 3,\n",
        "            \"default\": 0,\n",
        "            \"description\": \"Number of hours back to synchronize.\"\n",
        "          }\n",
        "        }\n",
        "      },\n",
        "      \"to\": {\n",
        "        \"auth\": \"service\",\n",
        "        \"dataset\": {\n",
        "          \"field\": {\n",
        "            \"name\": \"dataset\",\n",
        "            \"kind\": \"string\",\n",
        "            \"order\": 3,\n",
        "            \"default\": \"\",\n",
        "            \"description\": \"Existing dataset in BigQuery.\"\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "]\n",
        "\n",
        "json_set_fields(TASKS, FIELDS)\n",
        "\n",
        "project.initialize(_recipe={ 'tasks':TASKS }, _project=CLOUD_PROJECT, _user=USER_CREDENTIALS, _client=CLIENT_CREDENTIALS, _verbose=True)\n",
        "project.execute()\n"
      ]
    }
  ]
}